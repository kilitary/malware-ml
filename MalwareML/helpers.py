import os
import logging
import warnings
import numpy as np
from collections import defaultdict

from numpy import bincount
from sklearn.model_selection import StratifiedKFold

CATEGORY_BENIGN = 0
CATEGORY_MALICIOUS = 1


def expand_dirs(paths):
    """
    Takes a list of paths. If any are dirs, list the files in them. Not recursive, only one level deep.
    Return list of files, including any that were in the original paths list
    """
    for path in paths:
        if os.path.isdir(path):
            for item in os.listdir(path):
                yield(os.path.join(path,item))
        else:
            yield path

def get_file_lines(filepath, verbatim=False, no_empty=True):
    """
    Get lines from a file.
    If not verbatim, strip and split on #.
    Otherwise, just strip \n
    If no_empty, will skip empty lines
    """
    with open(filepath) as f:
        if verbatim:
            lines = [l.rstrip('\n') for l in f]
        else:
            lines = [l.split('#', 1)[0].strip() for l in f]

        if no_empty:
            lines = [l for l in lines if l]

    return lines


def get_weights_from_file(filepath):
    logging.info('Loading feature weights file')
    lines = get_file_lines(filepath, verbatim=False)
    weights = [l.rsplit(None, 1) for l in lines]
    logging.info('Done loading feature weights file')
    return weights


def get_imps_from_file(filepath):
    # NOTE: imps_dict is {imp: [hash, hash, ...]}, but each line in imps_file is hash, imp
    logging.info('Loading import address hash file')
    imps_dict = defaultdict(list)
    for line in get_file_lines(filepath):
        split = line.split(' ')
        imps_dict[split[1] if len(split) > 1 else ''].append(split[0])
    logging.info('Done loading import address hash file')
    return imps_dict


def remove_prefix(text, prefix):
    assert text.startswith(prefix)
    return text[len(prefix):]


def get_ml_params_from_env(env_prefix, cast_map):
    """
    Get environmental variables for classifier based on classifier_base_name
    :param: env_prefix: Only env. vars beginning with this prefix will be checked. The prefix will be stripped
    :param: cast_map: dict of <variable_name_without_prefix>: <callable_for_cast>. ex. "num_epochs": int
    :return: dict of <variable_name>: <value>. Values will be cast per variable_map
    """
    d = {}
    for k, v in os.environ.items():
        if not k.startswith(env_prefix):
            continue
        k = remove_prefix(k, env_prefix).lower()
        if k not in cast_map:
            continue
        if cast_map[k] == bool:  # bool('0') = True, so cast to int first
            v = int(v)
        d[k] = cast_map[k](v)
    return d


# noinspection PyAbstractClass
class ImpifiedKFold(StratifiedKFold):
    """
    We cheat here. X (features) is actually a list of hashes (in the same order as X)
    """

    @staticmethod
    def split_by_imp(hashes_by_imp, n_splits=4):
        """
        Splits hashes into even-ish groups with no imp in multiple groups
        :param hashes_by_imp: {<imp>: [<hash>, ...]}
        :param n_splits: number of groups to split into
        :return: [ <indices for split 0>, <indices for split 1>, ...]
        """
        groups = [[] for _ in range(n_splits)]
        for imp, hashes in sorted(hashes_by_imp.items(), key=lambda x: -len(x[1])):  # Sorted longest first
            group_to_add_to = min(groups, key=lambda x: len(x))
            group_to_add_to += hashes
        return groups

    def __init__(self, hashes_by_imp, *args, **kwargs):
        """
        :param hashes_by_imp: {<imp>: [<hash>, ...]}
        :param hashes: [<hash>, ...]. Same order as X
        """
        self.hashes_by_imp = hashes_by_imp
        super().__init__(*args, **kwargs)

    def _make_test_folds(self, X, y=None, groups=None):
        """
        Using self.hashes_by_imp, split into test folds with no imp in multiple folds
        :param X: List of hashes, in same order as samples
        :param y: Truths
        :param groups: Not used, for compatibility
        :return: Test fold index for each each sample, same order as X
        """
        hashes = np.asarray(X)

        # Omitted shuffle since we are going to sort the imps dict by length anyways
        # This part is copied from StratifiedKFold
        y = np.asarray(y)
        n_samples = y.shape[0]
        unique_y, y_inversed = np.unique(y, return_inverse=True)
        y_counts = bincount(y_inversed)
        min_groups = np.min(y_counts)

        if np.all(self.n_splits > y_counts):
            raise ValueError("All the n_groups for individual classes"
                             " are less than n_splits=%d."
                             % (self.n_splits))
        if self.n_splits > min_groups:
            warnings.warn(("The least populated class in y has only %d"
                           " members, which is too few. The minimum"
                           " number of groups for any class cannot"
                           " be less than n_splits=%d."
                           % (min_groups, self.n_splits)), Warning)

        # Here we diverge from StratifiedKFold
        test_folds = np.zeros(n_samples, dtype=np.int)
        for cls in unique_y:
            logging.debug('Splitting samples for cls {}'.format(cls))
            # First trim the hashes_by_imp to just contain the relevant hashes
            cls_hashes_list = list(hashes[y == cls])
            cls_hashes_set = set(cls_hashes_list)
            cls_test_folds = test_folds[y == cls]
            cls_hashes_by_imp = {k: [h for h in v if h in cls_hashes_set] for k, v in self.hashes_by_imp.items()}

            cls_hashes_by_imp_size = sum(len(v) for v in cls_hashes_by_imp.values())
            if cls_hashes_by_imp_size != len(cls_hashes_set):
                logging.debug('cls_hashes_by_imp size {} | cls_hashes size {}'.format(
                    cls_hashes_by_imp_size, len(cls_hashes_set)))
                raise ValueError("The cls_hashes_by_imp size doesn't match cls_hashes size."
                                 " Are all of the hashes in the hashes_by_imp dict? Check the imps_file?")

            # Now break into groups separated by imp hash
            cls_hash_splits = self.split_by_imp(cls_hashes_by_imp, self.n_splits)
            cls_index_splits = [[cls_hashes_list.index(x) for x in split] for split in cls_hash_splits]
            logging.debug('Split samples for cls {} into {} with lens {}'.format(
                cls, self.n_splits, str([len(x) for x in cls_index_splits])
            ))
            logging.debug('First element in hash split {}. According to index, matches {}'.format(
                cls_hash_splits[0][0], cls_hashes_list[cls_index_splits[0][0]]
            ))
            for test_fold_index, indices in enumerate(cls_index_splits):
                cls_test_folds[indices] = test_fold_index
            test_folds[y == cls] = cls_test_folds

        return test_folds
