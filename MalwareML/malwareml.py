#!/usr/bin/env python3
from __future__ import print_function
import json
import os
import sys
from timeit import default_timer as timer
import logging
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Imputer
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC, LinearSVC
from sklearn.gaussian_process.kernels import RBF
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict
from sklearn.pipeline import make_pipeline
from sklearn.externals import joblib

from sklearn.feature_extraction import DictVectorizer
from sklearn.manifold import TSNE
from matplotlib.colors import ListedColormap

logger = logging.getLogger('')

truths = ['true', 't', '1']
CV = os.environ.get('MML_CV', 'True').lower() in truths
SVM_C = float(os.environ.get('MML_SVM_C', 1000))
SVM_GAMMA = float(os.environ.get('MML_SVM_GAMMA', 0.02))
SVM_KERNEL = os.environ.get('MML_SVM_KERNEL', 'linear')
SVM_CACHE = int(os.environ.get('MML_SVM_CACHE_SIZE', '200'))
SVM_PROBABILITY = os.environ.get('MML_SVM_PROBABILITY', 'True').lower() in truths
EXCLUDE_FEATURE = os.environ.get('MML_EXCLUDE_FEATURE', None)
EXCLUDE_FEATURE_FILE = os.environ.get('MML_EXCLUDE_FEATURE_FILE', None)

CATEGORY_BENIGN = 0
CATEGORY_MALICIOUS = 1

log_dir = 'logs/'


class ML(object):
    def __init__(self):
        self.vec = None

    def build_feature_matrix(self, reports):
        # Pull all features from reports
        report_features = []
        for r in reports:
            # TODO: handle overwrite if report.name is the same
            report_features.append(r.features)

        # Vectorize into array
        self.vec = DictVectorizer()
        arr = self.vec.fit_transform(report_features).toarray()

        # Fill in missing values with avg value for that feature
        # TODO: Look into other(better?) ways to fill in values
        self.imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
        arr = self.imp.fit_transform(arr)
        # Standardize data to approx normal (mean 0 and unit variance)
        # self.scaler = StandardScaler()
        # arr = self.scaler.fit_transform(arr)

        return arr

    def get_feature_matrix(self, reports):
        """
        Used for experimenting. Uses existing DictVectorizer to convert reports to a matrix.
        Returns a feature matrix
        """
        for attr in ['vec', 'imp', 'scaler']:
            if getattr(self, attr, None) is None:
                raise Exception('You must call build_feature_matrix before using get_feature_matrix!')

        report_features = [r.features for r in reports]
        arr = self.vec.transform(report_features).toarray()
        arr = self.imp.transform(arr)
        arr = self.scaler.transform(arr)

        return arr

    def get_classifier(self, classifier):
        return self.classifiers[classifier]

    def get_acc_fp_fn(self, predictions_arr, truth_arr):
        # Assuming 0 = neg(benign), 1 = pos(malware)
        if (len(predictions_arr) != len(truth_arr)):
            logger.error("get_overall_acc(): Error predictions_arr and truth_arr are different sizes.")
            return -1

        correct_count = 0
        false_pos_count = 0
        false_neg_count = 0
        for i in range(len(predictions_arr)):
            if predictions_arr[i] == truth_arr[i]:
                correct_count += 1
            elif (predictions_arr[i] == 1) and (truth_arr[i] == 0):
                false_pos_count += 1
            elif (predictions_arr[i] == 0) and (truth_arr[i] == 1):
                false_neg_count += 1

        overall_acc = float(correct_count)/float(len(predictions_arr))
        return (overall_acc, false_pos_count, false_neg_count)

    def display_top_feature_weights(self, clf, n=15):
        feature_names = self.vec.get_feature_names()
        coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
        top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
        logger.info("\tTop Benign\t\t\tTop Malware")
        for (coef_1, fn_1), (coef_2, fn_2) in top:
            logger.info("\t%.4f\t%.15s\t\t%.4f\t%.15s" % (coef_1, fn_1, coef_2, fn_2))

    def CV_ml_params(self, pipe_clf, X_train, y_train):
        # Cross-validation ML Params
        c_range = np.logspace(-2, 3, 5)
        if (pipe_clf.get_params()['svc__kernel'] == 'rbf'):
            gamma_range = np.logspace(-9, 3, 5)
            param_grid = dict(svc__gamma=gamma_range, svc__C=c_range)
            CV_clf = GridSearchCV(estimator=pipe_clf, param_grid=param_grid, cv=5, n_jobs=4, verbose=20)
        else:
            param_grid = dict(svc__C=c_range)
            CV_clf = GridSearchCV(pipe_clf, param_grid=param_grid, cv=5, n_jobs=4)
        logger.info('GridSearchCV instantiated')
        CV_clf.fit(X_train, y_train)
        logger.info('GridSearchCV fitted')
        # gridCV_scores = CV_clf.cv_results_['mean_test_score']
        logger.info('Done cross validation')
        logger.info('The best parameters are ' + str(CV_clf.best_params_) + ' with a score of ' + str(CV_clf.best_score_))
        return CV_clf.best_params_

class Report(object):
    def __init__(self, category=None):
        self.name = ""
        self.features = {}
        self.total = None
        self.positives = None
        self.scans = None
        self.category = category

    def load_report(self, json_file, file_name="unknown"):
        """Load JSON formatted malware report. It can handle both a path to
        JSON file and a dictionary object."""
        if isinstance(json_file, str):
            self.json_path = json_file
            with open(json_file, "r") as malware_report:
                try:
                    self.report = json.load(malware_report)
                except ValueError as error:
                    logger.error("Could not load file; {} is not a valid JSON file.".format(malware_report))
                    logger.error("Exception: %s" % str(error))
                    # sys.exit(1)
                    return -1

        elif isinstance(json_file, dict):
            self.report = json_file
        else:
            # Unknown binary format
            logger.error("Could not load the data *{}* is of unknown type: {}.".format(json, type(json)))
            return -1

        # Could be extracted as features elsewhere...
        self.name = file_name
        # Get total and positives
        #self.total = self.report.get("virustotal", {}).get("total")
        #self.positives = self.report.get("virustotal", {}).get("positives")
        # Pull all VT normalised results
        #self.scans = self.report.get("virustotal", {}).get("scans")

        # Success
        return 1

    def get_features(self):
        self.features = self.report
        if EXCLUDE_FEATURE is not None and EXCLUDE_FEATURE in self.report:
            del(self.features[EXCLUDE_FEATURE])
        return

class ExcludedReport(Report):
    def __init__(self, *args, **kwargs):
        super().__init__()
        self.excluded_features = kwargs.pop('excluded_features', [])
        if self.excluded_features is None:
            self.excluded_features = []

    def get_features(self):
        super().get_features()
        if EXCLUDE_FEATURE is not None and EXCLUDE_FEATURE in self.report:
            del(self.features[EXCLUDE_FEATURE])
        for feat in self.excluded_features:
            if feat in self.features:
                del(self.features[feat])


def load_reports(directory_benign, directory_malware, excluded_features=None):
    reports = []
    reports_truth = []

    # Load in benign programs
    for file in os.listdir(directory_benign):
        # Ignore large report files...
        max_report_filesize = 20000000
        if (os.stat(os.path.join(directory_benign, file)).st_size > max_report_filesize):
            continue
        if excluded_features:
            new_report = ExcludedReport(category=CATEGORY_BENIGN, excluded_features=excluded_features)
        else:
            new_report = Report(category=CATEGORY_BENIGN)

        # Try to load report
        if(new_report.load_report(os.path.join(directory_benign, file), file) == -1):
            continue
        new_report.get_features()
        reports.append(new_report)
        reports_truth.append(CATEGORY_BENIGN)

    # Load in malware programs
    for file in os.listdir(directory_malware):
        # Ignore large report files...
        max_report_filesize = 20000000
        if (os.stat(os.path.join(directory_malware, file)).st_size > max_report_filesize):
            continue
        if excluded_features:
            new_report = ExcludedReport(category=CATEGORY_MALICIOUS, excluded_features=excluded_features)
        else:
            new_report = Report(category=CATEGORY_MALICIOUS)

        # Try to load report
        if(new_report.load_report(os.path.join(directory_malware, file), file) == -1):
            continue
        new_report.get_features()
        reports.append(new_report)
        reports_truth.append(CATEGORY_MALICIOUS)

    return (reports, reports_truth)

def plot_data(data_2d, labels):
    datasets = [(data_2d, labels)]
    names = ["Linear SVM"]
    classifiers = [SVC(kernel="linear", C=1.27)]

    h = .02
    #datasets = [(data_count, (X,y)), ...]
    figure = plt.figure(figsize=(27, 9))
    i = 1
    # iterate over datasets
    for ds_cnt, ds in enumerate(datasets):
        # preprocess dataset, split into training and test part
        X, y = ds
        X = StandardScaler().fit_transform(X)
        X_train, X_test, y_train, y_test = \
            train_test_split(X, y, test_size=.4, random_state=42)

        x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
        y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                             np.arange(y_min, y_max, h))

        # just plot the dataset first
        cm = plt.cm.RdBu
        cm_bright = ListedColormap(['#FF0000', '#0000FF'])
        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
        if ds_cnt == 0:
            ax.set_title("Input data")
        # Plot the training points
        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)
        # and testing points
        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.5)
        ax.set_xlim(xx.min(), xx.max())
        ax.set_ylim(yy.min(), yy.max())
        ax.set_xticks(())
        ax.set_yticks(())
        i += 1

        # iterate over classifiers
        for name, clf in zip(names, classifiers):
            ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
            clf.fit(X_train, y_train)
            score = clf.score(X_test, y_test)

            # Plot the decision boundary. For that, we will assign a color to each
            # point in the mesh [x_min, x_max]x[y_min, y_max].
            if hasattr(clf, "decision_function"):
                Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
            else:
                Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]

            # Put the result into a color plot
            Z = Z.reshape(xx.shape)
            ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)

            # Plot also the training points
            ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)
            # and testing points
            ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,
                       alpha=0.6)

            ax.set_xlim(xx.min(), xx.max())
            ax.set_ylim(yy.min(), yy.max())
            ax.set_xticks(())
            ax.set_yticks(())
            if ds_cnt == 0:
                ax.set_title(name)
            ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),
                    size=15, horizontalalignment='right')
            i += 1

    plt.tight_layout()
    plt.show()

def main():
    logger.info('Starting program')
    directory_benign = sys.argv[1]
    directory_malware = sys.argv[2]

    # Exclude Features from file, if specified
    excluded_features = None
    if EXCLUDE_FEATURE_FILE is not None:
        with open(EXCLUDE_FEATURE_FILE) as f:
            excluded_features = [j for j in [l.split('#', 1)[0].strip() for l in f if l] if j]

    # Load in reports
    (reports, reports_truth) = load_reports(directory_benign, directory_malware, excluded_features)
    logger.info('Done loading reports')

    # Init ML
    ml = ML()

    # Build numerical array from report features
    feat_matrix = ml.build_feature_matrix(reports)
    logger.info('Built matrix')

    # Visualization
    # model = TSNE(n_components=2, random_state=0)
    # model_out = model.fit_transform(feat_matrix)
    # print model_out
    # plot_data(model_out, reports_truth)

    # Initialize ML classifier
    clf = SVC(kernel=SVM_KERNEL, C=SVM_C, gamma=SVM_GAMMA)
    pipe_clf = make_pipeline(StandardScaler(), clf)
    if CV:
        start = timer()
        # X_train, X_test, y_train, y_test = train_test_split(feat_matrix, reports_truth, test_size=0.25, random_state=42)
        # best_params = ml.CV_ml_params(SVM_KERNEL, X_train, y_train)
        best_params = ml.CV_ml_params(pipe_clf, feat_matrix, reports_truth)
        cv_time = timer() - start
        pipe_clf.set_params(**best_params)
    else:
        cv_time = None


    # Train and predict
    start = timer()
    logger.info('Starting cross-val predict...')
    # cv_score = cross_val_score(pipe_clf, feat_matrix, reports_truth, cv=4)
    # logger.info(cv_score)
    predictions = cross_val_predict(pipe_clf, feat_matrix, reports_truth, cv=4, n_jobs=-1)
    logger.info('Predictions made')
    fit_predict_time = timer() - start

    # Output Information
    logger.info('Done ml')
    num_malware = len(os.listdir(directory_malware))
    num_benign = len(os.listdir(directory_benign))
    num_total = num_benign + num_malware
    logger.info("Total Number of Reports: " + str(num_total))
    logger.info("Number of Reports Included: " + str(len(reports)))
    logger.info("Number Malware: %d - Number Benign: %d" % (num_malware, num_benign))
    (score, f_pos, f_neg) = ml.get_acc_fp_fn(predictions, reports_truth)
    logger.info("Overall Accuracy: %.6f" % (score))
    logger.info("False Neg: %.2f%% - %d/%d, False Pos: %.2f%% - %d/%d"
          % (100 * float(f_neg) / float(num_malware), f_neg, num_malware, 100 * float(f_pos) / float(num_benign), f_pos, num_benign))
    logger.info("Number of Features: " + str(len(feat_matrix[0])))
    logger.info('Parameters: ' + str(pipe_clf.get_params()))
    # logger.info("C Value: " + str(pipe_clf.get_params()['svc__C']))
    # if pipe_clf.get_params()['svc__kernel'] == 'rbf':
    #     logger.info("Gamma Value: " + str(pipe_clf.get_params()['svc__gamma']))
    # logger.info("Kernel: " + str(pipe_clf.get_params()['svc__kernel']))
    if EXCLUDE_FEATURE:
        logger.info("Excluded feature: {}".format(EXCLUDE_FEATURE))
    if EXCLUDE_FEATURE_FILE:
        logger.info("Excluded feature file: {}".format(EXCLUDE_FEATURE_FILE))
    logger.info('')

    try:
        ml.display_top_feature_weights(clf)
    except Exception as e:
        logger.error('Could not display top features: {}'.format(e))
    logger.info('')

    stats = {
        'accuracy': score,
        'num_features': len(feat_matrix[0]),
        'kernel': clf.get_params()['kernel'],
        'C': clf.get_params()['C'],
        'gamma': clf.get_params().get('gamma', None),
        'exclude_feature': EXCLUDE_FEATURE,
        'exclude_feature_file': EXCLUDE_FEATURE_FILE,
        'exclude_features': excluded_features,
        'cv_time': str(cv_time),
        'fit_predict_time': str(fit_predict_time),
    }
    with open(os.path.join(log_dir, 'stats.json'), 'w') as f:
        json.dump(stats, f, indent=4)

"""
    results = {}
    for report in reports:
        if report in reports_train:
            res = 'train'
        else:
            prediction = predictions[reports_test.index(report)]
            res = '{} {}'.format(
                'true' if prediction == report.category else 'false',
                'positive' if prediction == CATEGORY_MALICIOUS else 'negative'
            )
        results[report.name] = res
    with open(os.path.join(log_dir, 'results.json'), 'w') as f:
        json.dump(results, f, indent=4)

    joblib.dump(clf, os.path.join(log_dir, 'clf.pkl'))
    joblib.dump(ml.vec, os.path.join(log_dir, 'vec.pkl'))
    joblib.dump(ml.imp, os.path.join(log_dir, 'imp.pkl'))
    #joblib.dump(ml.scaler, os.path.join(log_dir, 'scaler.pkl'))
"""

    # Precision = (# correctly predicted pos) / (# predicted pos), recall = (# correctly predicted pos) / (# actual positive)
    # logger.info(str(classification_report(y_test, predictions, target_names=['benign', 'malware'])))

if __name__ == '__main__':
    from logging_setup import setup_logging
    log_dir = setup_logging(from_file=__file__)
    main()
