import os
import re
import sys
import json
import random
import logging
import collections
from itertools import cycle
from helpers import ImpifiedKFold, CATEGORY_BENIGN, CATEGORY_MALICIOUS

import numpy as np
#import plotly.plotly as py
#from plotly.graph_objs import *
#import plotly.tools as tls
from sklearn.externals import joblib
from sklearn.metrics import auc, roc_curve
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction import DictVectorizer
from sklearn.preprocessing import StandardScaler, RobustScaler, FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict, train_test_split
from sklearn.decomposition import PCA as sklearnPCA
from sklearn.decomposition import IncrementalPCA as iPCA
from sklearn.base import BaseEstimator, TransformerMixin

logger = logging.getLogger(__name__)


class CustomScaler:
    def __init__(self, feature_map, feature_weights=None):
        if feature_weights is None:
            feature_weights = []

        self.weights = np.ones(len(feature_map))
        for f, w in feature_weights:
            if f not in feature_map:
                logger.error("Couldn't find {} in DictVectorizer vocab".format(f))
                continue
            self.weights[feature_map[f]] = w

    def __call__(self, X):
        return X * self.weights


class PCAScaler(BaseEstimator, TransformerMixin):
    def __init__(self, feature_map, column_regex, fr_cutoff=.80, fr_max_size=5000, fr_preferred_size=500, fr_batch_size=2000):

        vocab = feature_map
        self.fr_cutoff = fr_cutoff
        self.fr_max_size = fr_max_size
        self.fr_preferred_size = fr_preferred_size
        self.fr_batch_size = fr_batch_size
        self.weights = np.ones(len(vocab))
        self.PCA_indices = []
        self.PCAs = []
        # Get the indices of all columns we are interested in (based on regex)
        # PCA all the features
        if '*' == column_regex:
            logger.info('Using all features for PCA')
            tmp_indices = []
            for feature_name in vocab:
                tmp_indices.append(vocab[feature_name])
            if tmp_indices:
                self.PCA_indices.append(tmp_indices[:])
                logger.info('Got {} PCA-able features'.format(
                    len(self.PCA_indices[-1]))
                )
        # PCA all the following sigs separated by char '&'
        elif '&' in column_regex:
            regex_list = column_regex.split('&')
            logger.info('Using regex list: {} for PCA to reduce feature set size'.format(regex_list))
            for regex_index in range(len(regex_list)):
                tmp_indices = []
                for feature_name in vocab:
                    if re.search(regex_list[regex_index], feature_name):
                        tmp_indices.append(vocab[feature_name])
            if tmp_indices:
                self.PCA_indices.append(tmp_indices[:])
                logger.info('Got {} PCA-able features for regex {}'.format(
                    len(self.PCA_indices[-1]),regex_list)
                )
        # PCA each subset of features based on a list split by the char '|'
        elif '|' in column_regex:
            regex_list = column_regex.split('|')
            logger.info('Using regex list: {} for PCA to reduce feature set size'.format(regex_list))
            for regex_index in range(len(regex_list)):
                tmp_indices = []
                for feature_name in vocab:
                    if re.search(regex_list[regex_index], feature_name):
                        tmp_indices.append(vocab[feature_name])
                if tmp_indices:
                    self.PCA_indices.append(tmp_indices[:])
                    logger.info('Got {} PCA-able features for regex {}'.format(
                        len(self.PCA_indices[-1]),regex_list[regex_index])
                    )
        elif not column_regex:
            logger.info('Not PCAing anything!')
        else:
            logger.info('Using regex: {} for PCA to reduce feature set size'.format(column_regex))
            tmp_indices = []
            for feature_name in vocab:
                if re.search(column_regex, feature_name):
                    tmp_indices.append(vocab[feature_name])
            if tmp_indices:
                self.PCA_indices.append(tmp_indices[:])
                logger.info('Got {} PCA-able features for regex {}'.format(
                    len(self.PCA_indices[-1]),column_regex)
                )
        logger.info('Finished init for PCAScaler')

    def fit(self, X, y=None):
        for i, regex in enumerate(self.PCA_indices):
            if not regex:
                continue
            pca_matrix_in = X[:,regex]
            if self.fr_max_size == -1:
                logger.info('Running with fr_preferred_size of {}'.format(self.fr_preferred_size))
                pca_matrix_size = self.fr_preferred_size
            else:
                eig_vecs, eig_vals, v = np.linalg.svd(pca_matrix_in.T)
                tot = sum(eig_vals)
                var_exp = [(i / tot) * 100 for i in sorted(eig_vals, reverse=True)]
                cum_var_exp = np.cumsum(var_exp)
                pca_matrix_size = next(x[0] for x in enumerate(cum_var_exp) if x[1] > (self.fr_cutoff*100))
                if pca_matrix_size > self.fr_max_size:
                    logger.info('Tried to make PCA matrix {} features, but more than given max!'.format(pca_matrix_size))
                    pca_matrix_size = self.fr_max_size
            if pca_matrix_size < 1:
                logger.info('Got 0 features to PCA...')
                continue
            if pca_matrix_size >= len(regex):
                logger.info('PCAing the whole feature set...')
                pca_matrix_size = len(regex)
            if self.fr_batch_size == -1:
                logger.info('Running full PCA')
                self.PCAs.append(sklearnPCA(n_components=pca_matrix_size))
            else:
                logger.info('Running iPCA with batch size {}'.format(self.fr_batch_size))
                self.PCAs.append(iPCA(n_components=pca_matrix_size,batch_size=self.fr_batch_size))
            self.PCAs[i].fit(pca_matrix_in)
        return self

    def transform(self, X):
        pca_matrix_out = []
        indices_to_delete = []
        for i, regex in enumerate(self.PCA_indices):
            if not regex:
                continue
            pca_matrix_in = X[:, regex]
            pca_matrix_out.append(self.PCAs[i].transform(pca_matrix_in))
            indices_to_delete.extend(regex)
        logger.info('Started with {} features'.format(len(X[0])))
        X = np.delete(X, indices_to_delete, 1)
        logger.info('Length of remaining feature matrix: {}'.format(len(X[0])))
        logger.info('Appending PCA matrices now...')
        for matrix in pca_matrix_out:
            logger.info('Appending {} features'.format(len(matrix[0])))
            X = np.insert(X,len(X[0]),matrix.T,axis=1)
        logger.info('Length of new feature_matrix is {}'.format(len(X[0])))
        return X


class Classifier:
    model_items = ['scaler', 'custom_scaler',]  # To be used for load/save model
    type_map = dict(
        cv=int,
        n_jobs=int,
        fr_cutoff=float,
        fr_max_size=int,
        fr_preferred_size=int,
        fr_batch_size=int,
        fr_string=str,
        fr_type=str
    )  # For converting environmental variables to their proper type

    def __init__(self, cv=4, n_jobs=4, imps_dict=None, fr_cutoff=.80, fr_max_size=5000, fr_preferred_size=500, fr_batch_size=2000, fr_string='', fr_type='',
                 feature_include_patterns=None, feature_exclude_patterns=None, **kwargs):
        self.cv = cv
        self.n_jobs = n_jobs
        self.fr_cutoff = fr_cutoff
        self.fr_max_size = fr_max_size
        self.fr_preferred_size = fr_preferred_size
        self.fr_batch_size = fr_batch_size
        self.fr_string = fr_string
        self.fr_type = fr_type
        self.imps_dict = imps_dict
        self.feature_include_patterns = feature_include_patterns
        self.feature_exclude_patterns = feature_exclude_patterns
        self.folds = None

    def load_matrix_transformers(self, model_dir, restore_feature_indices=True):
        """
        param restore_feature_indices: If set, this will set the values of the feature map from the vectorizer vocab
        When using the matrix transformers to load a pre-filtered matrix (ex training with an existing matrix), this
        should be set to False
        When using the matrix transformers on a matrix directly from the vectorizer/imputer, this should be true
        """
        logging.info('Loading matrix components from {}'.format(model_dir))
        for name in ('vec', 'imp', 'feature_map'):
            setattr(self, name, joblib.load(os.path.join(model_dir, name+'.pkl')))
        if restore_feature_indices:
            self.feature_map = {k: self.vec.vocabulary_[k] for k in self.feature_map}

    def load_model(self, model_dir):
        self.load_matrix_transformers(model_dir)
        logging.info('Loading models from {}'.format(model_dir))
        if self.fr_type == 'PCA':
            self.model_items.append('pca_scaler')
        for name in self.model_items:
            setattr(self, name, joblib.load(os.path.join(model_dir, name+'.pkl')))

    def _build_classifier(self, *args, feature_matrix, **kwargs):
        """
        :param feature_matrix: KerasClassifier needs feature length on init, so we take the feature_matrix here.
        :return: classifier with fit and predict methods
        """
        raise NotImplementedError

    def fit_transform_feature_matrix(self, reports):
        """
        Fit and transform components required to convert report to feature matrix. Returns feature matrix.
        """
        report_features = [r.features for r in reports]
        logging.info('Building feature matrix')
        self.vec = DictVectorizer()
        self.imp = SimpleImputer(missing_values=np.nan, strategy='mean')
                    # Imputer(missing_values='NaN', strategy='mean', axis=0)  # Fill missing vals with avg for that feature
                    
        feature_matrix = self.vec.fit_transform(report_features)
        feature_matrix_arr = feature_matrix.toarray()

        # Remove any features that are all 0's or NaN's
        mask = np.ones(len(feature_matrix_arr[0]), np.bool)
        mask_remove_zeros = np.where(~feature_matrix_arr.any(axis=0))[0]
        mask_remove_nan = np.where(np.isnan(feature_matrix_arr).any(axis=0))[0]
        mask[mask_remove_zeros] = 0
        mask[mask_remove_nan] = 0
        feature_matrix = self.vec.restrict(mask)

        # Redo vectorizing and getting vocab
        feature_matrix = self.vec.transform(report_features).toarray()        
        self.feature_map = self.vec.vocabulary_
        feature_matrix = self.imp.fit_transform(feature_matrix)
        logging.info('Got {} features'.format(len(self.vec.feature_names_)))
        return feature_matrix

    def filter_feature_matrix(self, feature_matrix):
        """
        Filter the feature matrix based on supplied regex patterns. This is an AND operation,
        ie the feature must match at least one feature_include_pattern (if there are any)
        and cannot match any feature_exclude_pattern
        :param feature_matrix: feature_matrix to filter
        :return: feature_matrix
        """
        mask = np.zeros(feature_matrix.shape[1])
        logging.debug('Length of feature map before filtering: {}'.format(len(self.feature_map)))
        logging.debug('Length of mask: {}'.format(len(mask)))
        logging.debug('Largest value in feature map: {}'.format(max(self.feature_map.items(), key=lambda item: item[1])))
        if self.feature_include_patterns:
            self.feature_map = {k: v for k, v in self.feature_map.items()
                                if any(re.search(pat, k) for pat in self.feature_include_patterns)}
        if self.feature_exclude_patterns:
            self.feature_map = {k: v for k, v in self.feature_map.items()
                                if not any(re.search(pat, k) for pat in self.feature_exclude_patterns)}

        feature_map_sorted = sorted(self.feature_map.items(), key=lambda feature: feature[1])
        index = 0
        for k, v in feature_map_sorted:
            mask[v] = 1
            self.feature_map[k] = index
            index += 1
        logging.info('Keeping {} features'.format(sum(mask)))
        return feature_matrix[:, mask > 0]

    def _fit_transform_scalers(self, feature_matrix, feature_weights=None):
        """
        Fit and transform components required to scale feature matrix.
        self.vec needs to be set for FunctionTransformer.
        :param feature_weights: [('<feature_name>', <scaling_value>), ...]
        :return: feature_matrix
        """
        self.scaler = StandardScaler()
        feature_matrix = self.scaler.fit_transform(feature_matrix)
        self.custom_scaler = FunctionTransformer(CustomScaler(feature_map=self.feature_map, feature_weights=feature_weights))
        feature_matrix = self.custom_scaler.fit_transform(feature_matrix)
        if self.fr_type == 'PCA':
            self.pca_scaler = PCAScaler(feature_map=self.feature_map, column_regex=str(self.fr_string), fr_cutoff=self.fr_cutoff,
                                        fr_max_size=self.fr_max_size, fr_preferred_size=self.fr_preferred_size, fr_batch_size=self.fr_batch_size)
            feature_matrix = self.pca_scaler.fit_transform(feature_matrix,None)
        return feature_matrix

    def get_truths(self, reports):
        return np.array([r.truth for r in reports])

    def get_hashes(self, reports):
        return np.array([r.hash for r in reports])

    def _get_splits(self, features, classes, hashes=None, n_splits=4):
        """
        Splits the supplied args into n_splits
        :param n_splits: Number of splits
        :param hashes: [<hash>, ...]. Required iff self.imps_dict is not None.
        :return: Iterable of splits
        """
        random_state=random.randint(0,1000)
        logging.debug('Random state for kfold {}'.format(random_state))
        if self.imps_dict:
            kf = ImpifiedKFold(hashes_by_imp=self.imps_dict, n_splits=n_splits, random_state=random_state)
            return kf.split(hashes, classes)
        kf = StratifiedKFold(n_splits=n_splits, random_state=random_state)
        return kf.split(features, classes)

    def train(self, feature_matrix, truths, feature_weights=None, use_best_params=False):
        """
        Train classifier with feature_matrix and truths
        """
        logger.info('{} {}'.format(len(feature_matrix),len(feature_matrix[0])))
        feature_matrix_scaled = self._fit_transform_scalers(feature_matrix, feature_weights=feature_weights)
        self.clf = self._build_classifier(feature_matrix=feature_matrix_scaled)
        logging.info('Training classifier')
        if use_best_params:
            self.clf.set_params(**self.get_best_clf_params(feature_matrix, truths, feature_weights=feature_weights))
        logging.info('Parameters: ' + str(self.clf.get_params()))
        self.clf.fit(feature_matrix_scaled, truths, **self._get_fit_params())
        return self.clf

    def save_matrix_transformers(self, output_dir):
        """
        Saves only the components necessary to recreate the matrix, namely vectorizer and imputer
        :param output_dir: Directory to write to. Will be created if necessary
        """
        os.makedirs(output_dir, exist_ok=True)
        logging.info('Saving matrix components to {}'.format(output_dir))
        for name in ('vec', 'imp', 'feature_map'):
            joblib.dump(getattr(self, name), os.path.join(output_dir, name+'.pkl'))

    def save_model(self, output_dir):
        """
        Save components necessary for later prediction with this model
        :param output_dir: Directory to write to. Will write {vec,imp,scaler,clf}.pkl
        """
        os.makedirs(output_dir, exist_ok=True)
        self.save_matrix_transformers(output_dir)
        logging.info('Saving model components to {}'.format(output_dir))
        if self.fr_type == 'PCA':
            self.model_items.append('pca_scaler')
        for name in self.model_items:
            joblib.dump(getattr(self, name), os.path.join(output_dir, name+'.pkl'))

    def output_feature_stats(self, reports=None, path=''):
        """
        Write statistics on the run to path given.
        :param path: Directory to write to.
        :param reports: Reports to output features for.
        """
        with open(os.path.join(path, 'stats.txt'), 'w') as f:
            f.write('# ----- Model Features ({}) -----\n'.format(len(self.vec.feature_names_)))
            f.write('\n'.join(x for x in self.vec.feature_names_))
            f.write('\n\n')

            if reports is not None:
                found_features = sorted(set(feat for rep in reports for feat in rep.features))
                f.write('# ----- Found Features ({}) -----\n'.format(len(found_features)))
                # TODO add count and keep it in a utility function somewhere
                f.write('\n'.join(found_features))
                f.write('\n\n')

    def _get_param_grid(self):
        """
        Get param ranges to use when searching for optimal parameters
        :return: dict of 'param': <range>. ex. {'svc__C': np.logspace(-2, 3, 5)}
        """
        return {}

    def _get_test_params(self):
        """
        Params to set when testing (i.e. when model won't be used again later)
        :return: dict of 'param': <value_to_set>. Ex {'probability': False}
        """
        return {}

    def _get_cv_params(self):
        """
        Params to set when running with cross validation
        :return: dict of 'param': <value_to_set>. Ex {'probability': False}
        """
        return {**self._get_test_params(), **{}}

    def _get_roc_params(self):
        """
        Params to set for roc curve plotting. ROC needs probability, must be set if not enabled by default
        :return: dict of 'param': <value_to_set>. Ex {'probability': True}
        """
        return {}

    def _get_fit_params(self):
        """
        Additional params to use when calling 'fit'
        Note: The classifier will be in a pipeline, name params appropriately
        :return: dict of 'param': <value_to_set>. Ex {'kerasclassifier__verbose': 1)
        """
        return {}

    def _post_loop_cleanup(self):
        """
        When running classification in loop (ex. cross-validation), this is called at the end of each loop
        Used to free memory, re-initialize random variables, etc.
        """
        pass

    def _build_pipeline(self, classifier, feature_weights):
        if self.fr_type == 'PCA':
            return make_pipeline(
                StandardScaler(),
                #RobustScaler(),  # Terrible results
                FunctionTransformer(CustomScaler(self.feature_map, feature_weights)),
                PCAScaler(feature_map=self.feature_map, column_regex=str(self.fr_string), fr_cutoff=self.fr_cutoff,
                          fr_max_size=self.fr_max_size, fr_preferred_size=self.fr_preferred_size, fr_batch_size=self.fr_batch_size),
                classifier
            )
        else:
            return make_pipeline(
                StandardScaler(),
                #RobustScaler(),  # Terrible results
                FunctionTransformer(CustomScaler(self.feature_map, feature_weights)),
                classifier
            )

    def get_best_clf_params(self, feature_matrix, truths, feature_weights=None):
        """
        Get best ml params for the classifier using cross validation
        :return: best_params_, dict of "<param_name>": <best_value>
        """
        clf = self._build_classifier(feature_matrix=feature_matrix)
        clf.set_params(self._get_cv_params())
        pipe_clf = self._build_pipeline(clf, feature_weights)

        param_grid = self._get_param_grid()
        cv_clf = GridSearchCV(estimator=pipe_clf, param_grid=param_grid, cv=self.cv, n_jobs=self.n_jobs, verbose=20)

        logger.info('GridSearchCV instantiated')
        cv_clf.fit(feature_matrix, truths)
        logger.info('GridSearchCV fitted')
        logger.info('The best parameters are {} with a score of {}'.format(cv_clf.best_params_, cv_clf.best_score_))
        return cv_clf.best_params_

    def test(self, feature_matrix, truths, reports=None, train_indices=None, test_indices=None, feature_weights=None,
             test_size=0.25, predict_function='predict', param_overrides=None, use_best_params=False):
        """
        Tests the classifier with the given feature_matrix and truths
        If CV is greater than 1, uses cross-validation to test the entire set. Otherwise, only tests <test_size> of it
        :param feature_matrix: feature_matrix
        :param truths: list of truths (0 or 1)
        :param reports: Required in some cases. Ex. if using imps_dict to separate train/test by imp
        :param train_indices: Indices to use for training split. Will not use CV if present.
        Either both train_indices and test_indices or neither must be present.
        :param test_indices: Indices to use for test split. Will not use CV if present.
        Either both train_indices and test_indices or neither must be present.
        :param feature_weights: [('<feature_name>', <scaling_value>), ...]
        :param test_size: If not using cross validation, percent of the feature_matrix to use for testing
        :param predict_function: 'predict' for class predictions, 'predict_proba' for probabilities, etc.
        :param param_overrides: dict of additional parameters to set on pipeline
        :param use_best_params: Prior to testing, get the best parameters through grid search
        :return: <list of predictions>, <index of each prediction in <feature_matrix> > Ex. ([1,0,1,0], [3, 4, 0, 1])
        """
        # TODO implement n_jobs (we'd have to use joblib or something to parallelize testing)
        # TODO take test indices so we can run ensemble (want to test same indices with multiple classifiers)

        #self.clf = clf = self._build_classifier(feature_matrix=feature_matrix)
        #clf.set_params(**self._get_test_params())
        #pipe_clf = self._build_pipeline(clf, feature_weights)

        if test_indices is None and train_indices is None and self.cv and self.cv > 1:
            logging.info('Starting CV pipeline for accuracy testing')
            # predictions = cross_val_predict(pipe_clf, feature_matrix, truths, cv=CV, n_jobs=N_JOBS)
            # TODO test whether we can just pass StratifiedKFold to cross_val_predict
            # This should split and then run the same 'test, get_accuracy' cycle as otherwise
            if self.imps_dict:
                splits = list(self._get_splits(feature_matrix, truths, self.get_hashes(reports), n_splits=self.cv))
            else:
                splits = list(self._get_splits(feature_matrix, truths, n_splits=self.cv))
            prediction_blocks = []
            for i, (train_indices, test_indices) in enumerate(splits):
                x_train, x_test = feature_matrix[train_indices], feature_matrix[test_indices]
                y_train, y_test = truths[train_indices], truths[test_indices]
                x_train = self._fit_transform_scalers(x_train)
                x_test = self.get_scaled_feature_matrix(x_test)
                self.clf = clf = self._build_classifier(feature_matrix=x_train)
                clf.set_params(**self._get_test_params())
                if use_best_params:
                    self.clf.set_params(
                        **self.get_best_clf_params(feature_matrix, truths, feature_weights=feature_weights, ))
                if param_overrides is not None:
                    self.clf.set_params(**param_overrides)
                logging.info('Parameters: ' + str(self.clf.get_params()))
                self.clf.fit(x_train, y_train, **self._get_fit_params())
                prediction_block = getattr(self.clf, predict_function)(x_test)
                logging.info('')  # Because Keras doesn't output a newline after last epoch. (PR?)

                self.accuracy(truths, prediction_block, indices=test_indices, level=logging.DEBUG)
                prediction_blocks.append(prediction_block)
                self._post_loop_cleanup()

            if reports is not None:
                self.folds = {reports[test_index].hash: fold_index for fold_index, (_, test_indices) in enumerate(splits) for test_index in test_indices}
            return np.concatenate(prediction_blocks), np.concatenate([test_indices for _, test_indices in splits])

        else:
            logging.info('Starting accuracy testing')
            if train_indices is None and test_indices is None:
                x_train, x_test, y_train, y_test, _, test_indices = train_test_split(
                    feature_matrix, truths, range(len(truths)), test_size=test_size, stratify=truths
                )
            elif train_indices is None or test_indices is None:
                raise Exception("If you supply test or train indices, you must supply both")
            else:
                x_train, x_test = feature_matrix[train_indices], feature_matrix[test_indices]
                y_train, y_test = truths[train_indices], feature_matrix[test_indices]
            x_train = self._fit_transform_scalers(x_train)
            x_test = self.get_scaled_feature_matrix(x_test)
            self.clf = clf = self._build_classifier(feature_matrix=x_train)
            clf.set_params(**self._get_test_params())
            if use_best_params:
                self.clf.set_params(
                    **self.get_best_clf_params(feature_matrix, truths, feature_weights=feature_weights, ))
            if param_overrides is not None:
                self.clf.set_params(**param_overrides)
            logging.info('Parameters: ' + str(self.clf.get_params()))
            self.clf.fit(x_train, y_train, **self._get_fit_params())
            predictions = getattr(self.clf, predict_function)(x_test)
            logging.debug('')
            self._post_loop_cleanup()
            return predictions, test_indices

    def plot_roc(self, feature_matrix, truths, feature_weights=None):
        # Based on http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py
        import matplotlib.pyplot as plt  # Imported locally to reduce dependencies

        colors = cycle(['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange'])
        line_weight = 2

        clf = self._build_classifier(feature_matrix=feature_matrix)
        clf.set_params(**self._get_roc_params())
        pipe_clf = self._build_pipeline(clf, feature_weights)
        splits = self._get_splits(feature_matrix, truths, n_splits=self.cv)

        mean_tpr = 0.0
        mean_fpr = np.linspace(0, 1, 100)
        logging.info('Starting CV pipeline for roc plotting')
        for i, ((train_index, test_index), color) in enumerate(zip(splits, colors)):
            pipe_clf.fit(feature_matrix[train_index], truths[train_index])
            probabilities = pipe_clf.predict_proba(feature_matrix[test_index])
            # Compute ROC curve and area the curve
            fpr, tpr, thresholds = roc_curve(truths[test_index], probabilities[:, 1])
            mean_tpr += np.interp(mean_fpr, fpr, tpr)
            mean_tpr[0] = 0.0
            roc_auc = auc(fpr, tpr)
            plt.plot(fpr, tpr, lw=line_weight, color=color,
                     label='ROC fold %d (area = %0.2f)' % (i, roc_auc))
            self._post_loop_cleanup()

        plt.plot([0, 1], [0, 1], linestyle='--', lw=line_weight, color='k',
                 label='Luck')

        mean_tpr /= self.cv
        mean_tpr[-1] = 1.0
        mean_auc = auc(mean_fpr, mean_tpr)
        plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',
                 label='Mean ROC (area = %0.2f)' % mean_auc, lw=line_weight)

        plt.xlim([-0.05, 1.05])
        plt.ylim([-0.05, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver operating characteristic example')
        plt.legend(loc="lower right")
        plt.show()

    def accuracy(self, truths, predictions, indices=None, level=logging.WARNING):
        """
        :return: accuracy, false negative rate, false positive rate
        """
        if indices is not None:
            truths = truths[indices]
        assert len(predictions) == len(truths), 'Predictions and truths must be the same length'

        if isinstance(predictions[0], collections.Iterable):  # If this is class probabilities, convert to class number
            predictions = [np.argmax(p) for p in predictions]

        l = list(zip(predictions, truths))
        correct = sum(1 for p, t in l if p == t)
        fpos = sum(1 for p, t in l if p != t and t == CATEGORY_BENIGN)  # False Positives
        fneg = sum(1 for p, t in l if p != t and t == CATEGORY_MALICIOUS)  # False Negatives

        n = len(predictions)
        npos = sum(1 for t in truths if t == CATEGORY_MALICIOUS)
        nneg = sum(1 for t in truths if t == CATEGORY_BENIGN)

        accuracy = correct/n
        fnegrate, fposrate = fneg/npos, fpos/nneg

        logging.log(level, "Overall Accuracy: {:.6}".format(100*accuracy))
        logging.log(level, "False Neg: {:.4}% - {}/{}, False Pos: {:.4}% - {}/{}".format(
            100 * fnegrate, fneg, npos,
            100 * fposrate, fpos, nneg
        ))
        return accuracy, fnegrate, fposrate

    def get_prediction_category_string(self, prediction, truth):
        if isinstance(prediction, collections.Iterable):  # If this is class probabilities, convert to class number
            prediction = np.argmax(prediction)

        if truth is None:
            return 'unknown'

        if prediction == truth:
            return 'true positive' if truth == CATEGORY_MALICIOUS else 'true negative'
        else:
            return 'false positive' if truth == CATEGORY_BENIGN else 'false negative'

    def output_predictions(self, reports, predictions, indices=None, path='results.json'):
        """
        Outputs predictions in json format
        :param reports: list of Report objects
        :param predictions: [predicted class | (probabilities for each class) for each Report]
        :param indices: list of indices of predictions into the reports list. None if lists match
        :param path: path to output predictions to
        :return:
        """
        hashes, truths = self.get_hashes(reports), self.get_truths(reports)
        if indices is not None:
            hashes = np.asarray(hashes)[indices]
            truths = np.asarray(truths)[indices]

        #with open('prediction_results.txt', 'w') as f:
            #for ind, pred in zip(hashes, predictions, truths):
                #f.write('{} {pred[0]:.2f} {pred[1]:.2f}\n'.format(ind, pred=pred))
            #f.write('\n')

        #prediction_categories = [self.get_prediction_category_string(prediction, truth)
                                 #for prediction, truth in zip(predictions, truths)]
        results = {h: {
                        'category': self.get_prediction_category_string(prediction, truth),
                        'truth': int(truth) if truth is not None else -1,
                        'prediction': prediction.tolist(),
                        'fold': self.folds[h] if self.folds is not None else None,
                      }
                   for h, prediction, truth in zip(hashes, predictions, truths)}
        with open(path, 'w') as f:
            json.dump(results, f, indent=4, sort_keys=True)
            f.write('\n')

    # ----- Predicting from existing -----
    def get_feature_matrix(self, reports):
        """
        Uses existing components to convert reports to a matrix. Returns a feature matrix
        """
        report_features = [r.features for r in reports]
        logging.info('Getting feature matrix using existing components')
        feature_matrix = self.vec.transform(report_features).toarray()
        feature_matrix = self.imp.transform(feature_matrix)
        return feature_matrix

    def get_scaled_feature_matrix(self,feature_matrix):
        feature_matrix = self.scaler.transform(feature_matrix)
        feature_matrix = self.custom_scaler.transform(feature_matrix)
        if self.fr_type == 'PCA':
            feature_matrix = self.pca_scaler.transform(feature_matrix)
        return feature_matrix
    
    def get_predictions(self, feature_matrix, feature_weights=None):
        """
        Get predictions using existing classifier. Returns array of (class for each report)
        """
        logging.info('Predicting classes using existing classifier')
        feature_matrix_scaled = self.get_scaled_feature_matrix(feature_matrix)
        return self.clf.predict(feature_matrix_scaled)

    def get_distances(self, feature_matrix):
        """
        Get distance to hyperplane using existing classifier. Returns array of (distance to each class)
        """
        logging.info('Getting distances')
        feature_matrix_scaled = self.get_scaled_feature_matrix(feature_matrix)
        return self.clf.decision_function(feature_matrix_scaled)

    def get_probabilities(self, feature_matrix, log_proba=False):
        """
        Get probabilities of possible outcomes. Returns array of (probability for benign, malicious)
        """
        logging.info('Getting probabilities')
        feature_matrix_scaled = self.get_scaled_feature_matrix(feature_matrix)
        if log_proba:
            return self.clf.predict_log_proba(feature_matrix_scaled)
        return self.clf.predict_proba(feature_matrix_scaled)


class MultiClassifier(Classifier):
    """ Allows for multiple in a single class, chosen by classifier name in __init__"""
    classifiers = {}

    def __init__(self, classifier_name='', **kwargs):
        super().__init__(**kwargs)
        self.classifier_name = classifier_name
        self.classifier_dict = self.classifiers[classifier_name]

