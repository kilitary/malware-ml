#!/usr/bin/env python3
from __future__ import print_function

import importlib
import os
import sys
import logging
import argparse
import numpy as np
from collections import defaultdict

from custom_run import custom_test
from helpers import get_ml_params_from_env, get_file_lines, get_weights_from_file, get_imps_from_file
from helpers import expand_dirs, CATEGORY_BENIGN, CATEGORY_MALICIOUS
from report_loader import load_goodware_malware, load_files

# For reproducibility
# May not be working, not sure yet
# Based off https://github.com/fchollet/keras/issues/2280
#np.random.seed(42)
#import tensorflow as tf
#tf.set_random_seed(42)  # Mentioned in github, but doesn't seem to be needed.

DEFAULT_OUTDIR = './'
FIT_MODE, PREDICT_MODE = 'fit', 'predict'
MATRIX_SOURCE, FEATURE_SOURCE = 'matrix', 'features'


# ----- Machine Learning Functions -----
def train(ml, reports, feature_matrix, truths, output_dir, feature_weights=None, use_best_params=False):
    ml.train(feature_matrix, truths, feature_weights=feature_weights, use_best_params=use_best_params)
    ml.save_model(output_dir)


def predict(ml, reports, model_dir, results=False,
            get_predictions=False, get_distances=False, get_probabilities=True, get_log_probabilities=False):

    ml.load_model(model_dir=model_dir)
    feature_matrix = ml.get_feature_matrix(reports)
    feature_matrix = ml.filter_feature_matrix(feature_matrix)

    output = [report.name for report in reports]

    counts = defaultdict(int)
    if get_predictions:
        predictions = ml.get_predictions(feature_matrix)
        for val in predictions:
            counts[val] += 1
        output = zip(output, predictions)
    if get_probabilities:
        predictions = ml.get_probabilities(feature_matrix, log_proba=False)
        for val in predictions:
            counts[int(val[0]<0.5)] += 1
        output = zip(output, predictions)
    if get_log_probabilities:
        output = zip(output, ml.get_probabilities(feature_matrix, log_proba=True))
    if get_distances:
        output = zip(output, ml.get_distances(feature_matrix))

    logging.debug('Results:')
    print('\n'.join(str(x) for x in output))

    if get_probabilities or get_predictions:
        logging.debug('Counts {}'.format(counts))
        try:
            total = counts[0] + counts[1]
            logging.info("p {:.2f}% ({}) n {:.2f}% ({})".format(100*counts[1]/total, counts[1], 100*counts[0]/total, counts[0]))
        except:
            logging.error('Something went wrong printing counts. Had {} counts'.format(len(counts)))

    if results:
        if get_probabilities or get_predictions:
            ml.output_predictions(reports, predictions)
        else:
            logging.error("Cannot output results, don't have predictions or probabilities")


def test(ml, reports, feature_matrix, truths, probabilities=True, feature_weights=None, use_best_params=False,
         results=False):

    kwargs = {}
    if probabilities:
        kwargs['predict_function'] = 'predict_proba'

    predictions, indices = ml.test(feature_matrix, truths, reports=reports, feature_weights=feature_weights,

                                   use_best_params=use_best_params, **kwargs)
    ml.accuracy(truths, predictions, indices=indices)
    if results:
        ml.output_predictions(reports, predictions, indices=indices)


def roc(ml, reports, feature_matrix, truths, feature_weights=None, use_best_params=False):
    ml.plot_roc(feature_matrix, truths, feature_weights=feature_weights)


def save_matrix(ml, reports, feature_matrix, truths, matrix_dir='matrix', feature_weights=None, use_best_params=False):
    """
    Saves the feature_matrix, truths, hashes, vectorizer, and imputer
    :param ml: used to get the vectorizer and imputer for saving
    :param reports: list of report for each sample. Will be used to save hashes
    :param feature_matrix: feature_matrix to save.
    :param truths: list of true value for each sample
    :param matrix_dir: Directory to load matrix and related from
    :param feature_weights: Unused. For compatibility only.
    :param use_best_params: Unused. For compatibility only.
    """
    os.makedirs(matrix_dir, exist_ok=True)
    logging.info('Saving feature matrix, truths, and hashes')
    np.save(os.path.join(matrix_dir, 'feature_matrix.npy'), feature_matrix)
    np.save(os.path.join(matrix_dir, 'truths.npy'), truths)
    np.save(os.path.join(matrix_dir, 'hashes.npy'), ml.get_hashes(reports))

    # Save readable copy of feature map for quick ref
    with open(os.path.join(matrix_dir, 'feature_map.txt'), 'w') as f:
        f.write('\n'.join(sorted('{} {}'.format(k, v) for k, v in ml.feature_map.items())))
        f.write('\n')

    logging.info('Saving matrix components (ie. vectorizer and imputer)')
    ml.save_matrix_transformers(matrix_dir)


def load_matrix_dir(matrix_dir, ml):
    """
    :param matrix_dir: Directory to load feature matrix and related from
    :param ml: Classifier to set vectorizer and imputer on
    :return: feature_matrix, truths, reports (faked)
    """
    feature_matrix = np.load(os.path.join(matrix_dir, 'feature_matrix.npy'))
    truths = np.load(os.path.join(matrix_dir, 'truths.npy'))
    hashes = np.load(os.path.join(matrix_dir, 'hashes.npy'))

    ml.load_matrix_transformers(matrix_dir, restore_feature_indices=False)

    # Reports is needed if we are outputting results or using imps_dict
    FakeReport = type('FakeReport', (), {})
    reports = []
    for h, t in zip(hashes, truths):
        report = FakeReport()
        report.hash = report.name = h
        report.truth = t
        reports.append(report)

    return feature_matrix, truths, reports


# ----- Setup Functions -----
def build_parser():
    """
    Build the argparse parser.
    :return: argparse.ArgumentParser instance
    """
    parser = argparse.ArgumentParser(description='Train, predict, or test machine learning for malware detection')
    parser.add_argument('-v', '--verbose', action='count', default=0, help='-v for info, -vv for debug')
    parser.add_argument('-q', '--quiet', action='store_true', help='Ignore warnings, only output errors')
    parser.add_argument('-s', '--max-filesize', help='Maximum report size to parse. Default unlimited')
    parser.add_argument('-e', '--extract-features', action='store_true',
                        help="Extract features from file. Set if inputting cuckoo reports instead of feature files")
    parser.add_argument('--feature-include-file', help='File of regex patterns to include features by')
    parser.add_argument('--feature-exclude-file', help='File of regex patterns to exclude features by')
    parser.add_argument('--stats', action='store_true', help='Output stats for the run to ./stats.txt')
    subparsers = parser.add_subparsers(title='commands', help='Use --help to get options for a specific command')
    subparsers.required = True
    subparsers.dest = argparse.SUPPRESS

    # ----- Components -----
    # Takes feature matrix
    matrix_parser = argparse.ArgumentParser(add_help=False)
    matrix_parser.add_argument('matrix_dir', help='Path to directory with feature matrix and related')
    matrix_parser.set_defaults(source=MATRIX_SOURCE)

    # Takes goodware malware
    feature_parser = argparse.ArgumentParser(add_help=False)
    feature_parser.add_argument('goodware', metavar='goodware-dir', help='Path to dir of goodware reports/features')
    feature_parser.add_argument('malware', metavar='malware-dir', help='Path to dir of malware reports/features')
    feature_parser.set_defaults(source=FEATURE_SOURCE)

    # Common options
    fitting_parser = argparse.ArgumentParser(add_help=False)
    fitting_parser.add_argument('--use-best-params', action='store_true',
                                help='Get best machine learning parameters using cross validation and use them')
    fitting_parser.add_argument('--feature-weight-file', help='\\n separated, <regex pattern> <scaling factor>')
    fitting_parser.add_argument('--imps-file', help='\\n separated, <hash> <imp>. Blank imp ok')
    fitting_parser.set_defaults(mode=FIT_MODE)

    # fitting + feature loading
    feature_fitting_parser = argparse.ArgumentParser(add_help=False, parents=[fitting_parser, feature_parser])
    # fitting + matrix loading
    matrix_fitting_parser = argparse.ArgumentParser(add_help=False, parents=[fitting_parser, matrix_parser])

    # ----- Train parsers -----
    train_parser = argparse.ArgumentParser(add_help=False)
    train_parser.add_argument('-o', '--output-dir', default=DEFAULT_OUTDIR, help='Path to output dir for models.')
    train_parser.set_defaults(func=train)

    subparsers.add_parser('train', parents=[train_parser, feature_fitting_parser],
                          help='Train model using given goodware/malware feature files')
    subparsers.add_parser('train-matrix', parents=[train_parser, matrix_fitting_parser],
                          help='Train model using given matrix dir path')

    # ----- Test parsers -----
    test_parser = argparse.ArgumentParser(add_help=False)
    test_parser.add_argument('--results', action='store_true', help='Output prediction results to ./results.json')
    test_parser.add_argument('--probabilities', action='store_true', help="Get probabilities (default)")
    test_parser.add_argument('--no-probabilities', dest='probabilities', action='store_false', help="Don't get prob")
    test_parser.set_defaults(probabilities=True)
    test_parser.set_defaults(func=test)

    subparsers.add_parser('test', parents=[test_parser, feature_fitting_parser],
                          help='Test ML accuracy on provided goodware/malware feature files')
    subparsers.add_parser('test-matrix', parents=[test_parser, matrix_fitting_parser],
                          help='Test ML accuracy on provided matrix')

    custom_test_parser = subparsers.add_parser('custom-test', parents=[feature_fitting_parser])
    custom_test_parser.set_defaults(func=custom_test)

    # ----- ROC -----
    roc_parser = subparsers.add_parser('roc', parents=[feature_fitting_parser],
                                       help='Plot ROC curve for goodware/malware feature files')
    roc_parser.set_defaults(func=roc)

    # ----- Predict parser -----
    # TODO predict should run from matrix too
    # But it should load vectorizer and imputer from matrix dir as before
    # So the model HAS to have been built with the same vectorizer/imputer
    predict_parser = subparsers.add_parser('predict', help='Use existing model to predict classes for input samples'
                                                           'Outputs "1" for malicious, (one line per sample)')
    predict_parser.add_argument('-m', '--model-dir', required=True,
                                help='Path to dir with clf.pkl, vec.pkl, arr.pkl, and imp.pkl.')
    predict_parser.add_argument('files', metavar='FILE', nargs='*', help="Samples to process.")

    predict_parser.add_argument('--predictions', dest='get_predictions', action='store_true',
                                help="Print predictions (0 or 1)")
    predict_parser.add_argument('--no-predictions', dest='get_predictions', action='store_false')
    predict_parser.add_argument('--distances', dest='get_distances', action='store_true',
                                help="Print distance from sample to hyperplane")
    predict_parser.add_argument('--no-distances', dest='get_distances', action='store_false')
    predict_parser.add_argument('--probabilities', dest='get_probabilities', action='store_true',
                                help="Print probabilities (default)")
    predict_parser.add_argument('--no-probabilities', dest='get_probabilities', action='store_false')
    predict_parser.set_defaults(get_probabilities=True)
    predict_parser.add_argument('--log-probabilities', dest='get_log_probabilities', action='store_true',
                                help="Print logarithmic probabilities")
    predict_parser.add_argument('--no-log-probabilities', dest='get_log_probabilities', action='store_false')
    predict_parser.add_argument('--results', action='store_true', help='Output prediction results to ./results.json')
    predict_parser.set_defaults(source=FEATURE_SOURCE)
    predict_parser.set_defaults(mode=PREDICT_MODE)
    predict_parser.set_defaults(func=predict)

    # ----- Matrix parser -----
    matrix_parser = subparsers.add_parser('save-matrix', parents=[feature_parser],
                                           help='Save feature matrix and related info to specified dir')
    matrix_parser.add_argument('matrix_dir', help='Dir to save matrix and related. Will be created if necessary')
    matrix_parser.set_defaults(mode=FIT_MODE)
    matrix_parser.set_defaults(func=save_matrix)

    return parser


def setup_logging(verbosity=0):
    """
    Setup logging
    :param verbosity: verbosity level. <1 is ERROR, 0 is normal (WARNING), 1 is INFO, >1 is DEBUG
    :return: logger instance. You likely won't need it, just use the logging module directly.
    """
    logger = logging.getLogger('')
    if verbosity > 1:
        logger.setLevel(logging.DEBUG)
    elif verbosity == 1:
        logger.setLevel(logging.INFO)
    elif verbosity == 0:
        logger.setLevel(logging.WARNING)
    elif verbosity < 0:
        logger.setLevel(logging.ERROR)

    logging.info('Starting program')
    logging.debug('Ran as:')
    logging.debug(sys.argv)
    logging.debug('pwd: {}'.format(os.path.abspath(os.curdir)))

    return logger


def get_classifier_class(classifier_name):
    """
    Dynamically load and return the ClassifierClass based on passed in string
    :param classifier_name: classifier base name and (optionally) specific name. ex. 'SK-SVM-RBF'
    :return: ClassifierClass and clf_params with initial params
    """
    split = classifier_name.split('-', 1)
    classifier_base, classifier_specific = split[0], split[1] if len(split) > 1 else None
    classifier = importlib.import_module(classifier_base + '_classifier')
    # noinspection PyPep8Naming
    ClassifierClass = getattr(classifier, classifier_base.title() + 'Classifier')
    clf_params = get_ml_params_from_env(env_prefix='MML_', cast_map=ClassifierClass.type_map)
    if classifier_specific:
        clf_params['classifier_name'] = classifier_specific

    return ClassifierClass, clf_params


def main(argv, classifier_name):
    # Command line args
    cargs = build_parser().parse_args(argv[1:])
    cargs = vars(cargs)  # Convert to dict

    # Logging
    setup_logging(-1 if cargs.pop('quiet') else cargs.pop('verbose'))
    logging.debug('Parsed args: {}'.format(cargs))

    # Classifier
    # noinspection PyPep8Naming
    ClassifierClass, clf_params = get_classifier_class(classifier_name)

    source = cargs.pop('source')
    mode = cargs.pop('mode')
    stats = cargs.pop('stats', False)

    feature_include_file = cargs.pop('feature_include_file', None)
    feature_exclude_file = cargs.pop('feature_exclude_file', None)
    if feature_include_file is not None:
        clf_params['feature_include_patterns'] = get_file_lines(feature_include_file, verbatim=True, no_empty=True)
    if feature_exclude_file is not None:
        clf_params['feature_exclude_patterns'] = get_file_lines(feature_exclude_file, verbatim=True, no_empty=True)

    loading_params = dict(  # Really these shouldn't be present if we are using the matrix, but what can you do?
        extract_features=cargs.pop('extract_features'),
        max_filesize=cargs.pop('max_filesize', None),
    )

    # Call appropriate function by mode
    if mode == FIT_MODE:
        # Feature weights
        feature_weights_file = cargs.pop('feature_weight_file', None)
        feature_weights = get_weights_from_file(feature_weights_file) if feature_weights_file else None

        # Imps
        imps_file = cargs.pop('imps_file', None)
        if imps_file:
            clf_params['imps_dict'] = get_imps_from_file(imps_file)

        # Classifier
        ml = ClassifierClass(**clf_params)
        if source == FEATURE_SOURCE:
            reports = load_goodware_malware(cargs.pop('goodware'), cargs.pop('malware'), **loading_params)
            feature_matrix, truths = ml.fit_transform_feature_matrix(reports), ml.get_truths(reports)
            feature_matrix = ml.filter_feature_matrix(feature_matrix)
        elif source == MATRIX_SOURCE:
            feature_matrix, truths, reports = load_matrix_dir(cargs.pop('matrix_dir'), ml)
            feature_matrix = ml.filter_feature_matrix(feature_matrix)
        else:
            raise NotImplementedError

        matrix_length = os.environ.pop('MML_MATRIX_LENGTH', None)
        if matrix_length:
            matrix_length = int(matrix_length)

            # find n samples from each category
            good_matching = np.where(truths==CATEGORY_BENIGN)[0][:matrix_length]
            mal_matching = np.where(truths==CATEGORY_MALICIOUS)[0][:matrix_length]
            matching = np.concatenate((good_matching, mal_matching))
            feature_matrix = feature_matrix[matching]
            truths = truths[matching]

        # Go!
        cargs.pop('func')(ml, reports, feature_matrix, truths, feature_weights=feature_weights, **cargs)

    elif mode == PREDICT_MODE:
        ml = ClassifierClass(**clf_params)
        files = list(expand_dirs(cargs.pop('files')))
        reports = load_files(files, truths=None, **loading_params)
        cargs.pop('func')(ml, reports, **cargs)

    else:
        raise NotImplementedError

    # Output some statistics
    if stats:
        # TODO add output directory option
        ml.output_feature_stats(reports)

    logging.info('Done')


if __name__ == '__main__':
    main(sys.argv, classifier_name=os.environ.get('MML_CLASSIFIER', 'SK-SVM-RBF').lower())
